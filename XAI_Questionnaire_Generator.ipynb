{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6f8126-7f42-43d6-9f85-99fa0ba6e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Import\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5eb449-306c-4591-94fd-73dd1ae6d236",
   "metadata": {},
   "source": [
    "# XAI Questionnaire Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06200be9-b0a8-475f-9766-732868644c4c",
   "metadata": {},
   "source": [
    "The following notebook has been created with the aim of generating a template of a questionnaire suitable for making evaluation in the XAI field. \n",
    "\n",
    "In order to generate a survey template suited for the user's needs, the following program requires you to answer the questions below. Later, after clicking the button 'Generate Template', the program will save the template in a file with the .ipynb extension that contains, in addition to the survey template, all the information necessary to deploy it.\n",
    "\n",
    "If you run this notebook in a Google Colaboratory environment, uncomment the last cell to download a zip file containing all the files produced by this notebook on your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcbfd81-b4fc-4027-b0ba-a094f71e62fb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a7cd65-f01e-4567-a94a-b00216dc2010",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Question 1\n",
    "\n",
    "#### Qualitative Evaluation\n",
    "* A qualitative evaluation consists of open-ended questions. The questions' answers are more complex to analyse than quatitative evaluation, but it allows to do deeper analysis on the answers.\n",
    "\n",
    "#### Quantitative Evaluation\n",
    "* A quantitative evaluation consists on close-ended questions. The following evaluation allows to do statistical analysis easier than qualitative evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2b8220-7e76-4faa-8a1b-c5e1aa11721e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Considering the following definitions, what type of evaluation you would like to do in your questionnaire?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ceb4682-ce15-4b51-abfa-14c431b56886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021ca51cfbb44db59e0d5f6a19e6d115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=(('Qualitative Evaluation', '1'), ('Quantitative Evaluation', '2')), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation_type = question1RadioButtons()\n",
    "evaluation_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee956d96-0ea5-4922-ae48-4053fca6ac5d",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b913e-b225-4993-b1a7-1b43b8e48ba2",
   "metadata": {},
   "source": [
    "The evaluation that we normally would like to make when carrying out a questionnaire in the XAI field, is to evaluate whether the explanation generated by our XAI system satisfies one or more of the following goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd2a1ac8-2420-4ac9-a020-815a3dadcb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc69fd84fb5424cbe574d2c7cc780c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x04\\x99\\x00\\x00\\x02\\x0b\\x08\\x06\\x00\\x00\\x00K\\xb4MY\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_1 = open(\"./Images/Explanation_Goals.png\", \"rb\")\n",
    "widgets.Image(\n",
    "    value=image_1.read(),\n",
    "    format='png',\n",
    "    width=589,\n",
    "    height=262,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca34386-df55-466f-be6f-8f9d430fbdbd",
   "metadata": {},
   "source": [
    "To test the hypothesis, it is necessary to use a methodology. Four different methodologies can be used for this purpose, and each differs in the evaluation method and information provided to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da54d2c-c036-4bd6-ac51-bdf8c9129364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd59f7d0c1b4447af718400afc7a6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x05\"\\x00\\x00\\x01o\\x08\\x06\\x00\\x00\\x00^\\xa1\\xb5\\x86\\x…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_2 = open(\"./Images/Methodology_Assessment_Explanation_Quality.png\", \"rb\")\n",
    "widgets.Image(\n",
    "    value=image_2.read(),\n",
    "    format='png',\n",
    "    width=589,\n",
    "    height=262,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f2a178-d166-4df0-8fb8-d7c0bf3987a8",
   "metadata": {},
   "source": [
    "Considering the provided information, which methodology would you like to use to test the explanation goal/goals you fixed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "347e6319-0850-4cbb-ace1-4902b8d927b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0077edb8c0d94bc98c37dda666774d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=(('Verification Task', '1'), ('Forced Choice', '2'), ('Forward Simulation', '3'), ('Count…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explanation_assessment_quality = question2RadioButtons()\n",
    "explanation_assessment_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f07d28-3bcd-441b-9d19-e603770932db",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa8a5ff-80d7-4771-91eb-a92e47955057",
   "metadata": {},
   "source": [
    "How many questions would you like to have in your questionnaire? The maximum selection is bonded to 5 not to have a too long questionnaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b350b5e9-c913-482c-9c5f-0c50f96231cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f51ebbc272849f38795f76d921a9828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(options=(('1', '1'), ('2', '2'), ('3', '3'), ('4', '4'), ('5', '5')), value=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "questions_number = question3RadioButtons()\n",
    "questions_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "180c7902-7915-4291-9075-215af86f20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_button = widgets.Button(\n",
    "    description='Generate Template'\n",
    ")\n",
    "output = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "551a8942-f7e6-4f2f-bc78-063934a7685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_button_clicked(b):\n",
    "    output.clear_output()\n",
    "    if evaluation_type.value != None and explanation_assessment_quality != None and questions_number != None:\n",
    "        templateGenerator(evaluation_type.value, explanation_assessment_quality.value, questions_number.value)\n",
    "        \n",
    "        with output:\n",
    "            print('Template Generated')\n",
    "    else:\n",
    "        with output:\n",
    "            print('Please, answers to all the questions')\n",
    "        return\n",
    "\n",
    "generate_button.on_click(generate_button_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd83d0c8-4ec9-4441-9504-3c32303a6cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5012991d03411885f659b33d49f561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Generate Template', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ee6d3e498042858ea741e5150f236f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(generate_button,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84200c6f-8236-4079-a096-fb0d4b93a73f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
